"GGUF"
"general.type"
"general.architecture"
"general.quantization_version"
"general.alignment"
"general.name"
"general.author"
"general.version"
"general.url"
"general.description"
"general.license"
"general.source.url"
"general.source.huggingface.repository"
"vocab_size"
"context_length"
"embedding_length"
"block_count"
"leading_dense_block_count"
"feed_forward_length"
"expert_feed_forward_length"
"expert_shared_feed_forward_length"
"use_parallel_residual"
"tensor_data_layout"
"expert_count"
"expert_used_count"
"expert_shared_count"
"expert_weights_scale"
"pooling_type"
"logit_scale"
"decoder_start_token_id"
"attn_logit_softcapping"
"final_logit_softcapping"
"attention.head_count"
"attention.head_count_kv"
"attention.max_alibi_bias"
"attention.clamp_kqv"
"attention.key_length"
"attention.value_length"
"attention.layer_norm_epsilon"
"attention.layer_norm_rms_epsilon"
"attention.causal"
"attention.q_lora_rank"
"attention.kv_lora_rank"
"attention.relative_buckets_count"
"attention.sliding_window"
"rope.dimension_count"
"rope.freq_base"
"rope.scale_linear"
"rope.scaling.type"
"rope.scaling.factor"
"rope.scaling.attn_factor"
"rope.scaling.original_context_length"
"rope.scaling.finetuned"
"rope.scaling.yarn_log_multiplier"
"split.no"
"split.count"
"split.tensors.count"
"ssm.conv_kernel"
"ssm.inner_size"
"ssm.state_size"
"ssm.time_step_rank"
"ssm.dt_b_c_rms"
"tokenizer.ggml.model"
"tokenizer.ggml.pre"
"tokenizer.ggml.tokens"
"tokenizer.ggml.token_type"
"tokenizer.ggml.token_type_count"
"tokenizer.ggml.scores"
"tokenizer.ggml.merges"
"tokenizer.ggml.bos_token_id"
"tokenizer.ggml.eos_token_id"
"tokenizer.ggml.unknown_token_id"
"tokenizer.ggml.seperator_token_id"
"tokenizer.ggml.padding_token_id"
"tokenizer.ggml.cls_token_id"
"tokenizer.ggml.mask_token_id"
"tokenizer.ggml.add_bos_token"
"tokenizer.ggml.add_eos_token"
"tokenizer.ggml.add_space_prefix"
"tokenizer.ggml.remove_extra_whitespaces"
"tokenizer.ggml.precompiled_charsmap"
"tokenizer.huggingface.json"
"tokenizer.rwkv.world"
"tokenizer.ggml.prefix_token_id"
"tokenizer.ggml.suffix_token_id"
"tokenizer.ggml.middle_token_id"
"tokenizer.ggml.eot_token_id"
"tokenizer.ggml.eom_token_id"
"adapter.type"
"adapter.lora.alpha"
"adapter.type"
"adapter.lora.alpha"
"llama"
"falcon"
"grok"
"gpt2"
"gptj"
"gptneox"
"mpt"
"baichuan"
"starcoder"
"refact"
"bert"
"nomic-bert"
"jina-bert-v2"
"bloom"
"stablelm"
"qwen"
"qwen2"
"qwen2moe"
"phi2"
"phi3"
"plamo"
"codeshell"
"orion"
"internlm2"
"minicpm"
"gemma"
"gemma2"
"starcoder2"
"mamba"
"xverse"
"command-r"
"dbrx"
"olmo"
"openelm"
"arctic"
"deepseek2"
"chatglm"
"bitnet"
"t5"
"t5encoder"
"jais"
"nemotron"
"exaone"
"pattern"
"minLength"
"maxLength"
"root"
"maximum"
"minimum"
"exclusiveMaximum"
"maxItems"
"minItems"
"{"
"}"
"items"
"type"
"enum"
"root"
