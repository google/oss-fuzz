#!/usr/bin/env python3
# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
################################################################################

"""
Universal Plugin Generator
Creates plugins for both programming languages and human languages
"""

import sys
from pathlib import Path
from typing import Dict, List
import re

class UniversalPluginGenerator:
    """Generates plugins for the universal fuzzing platform"""

    def __init__(self):
        self.plugins_dir = Path(__file__).parent / "plugins"
        self.plugins_dir.mkdir(exist_ok=True)

    def create_programming_language_plugin(self, lang_name: str, plugin_name: str,
                                          extensions: List[str], keywords: List[str],
                                          function_patterns: List[str], fuzzer_engine: str) -> str:
        """Create a programming language plugin"""

        plugin_name = re.sub(r'[^a-zA-Z0-9_]', '_', plugin_name).lower()

        template = f'''#!/usr/bin/env python3
"""
{lang_name} Language Detection Plugin
Generated by Universal Plugin Generator
"""

from pathlib import Path
from typing import Dict, Any, List
import re
import sys

# Add the parent directory to the path for imports
parent_dir = Path(__file__).parent.parent
sys.path.insert(0, str(parent_dir))

from rapid_expand import LanguagePlugin, PluginResult

class {plugin_name.title()}LanguagePlugin(LanguagePlugin):
    """Plugin for detecting and analyzing {lang_name} code"""

    @property
    def name(self) -> str:
        return "{plugin_name}"

    @property
    def supported_extensions(self) -> List[str]:
        return {extensions}

    @property
    def language_name(self) -> str:
        return "{lang_name}"

    @property
    def fuzzer_engine(self) -> str:
        return "{fuzzer_engine}"

    def detect_language(self, file_path: Path) -> PluginResult:
        """Detect if a file is written in {lang_name}"""
        try:
            content = file_path.read_text(encoding='utf-8', errors='ignore')

            # Language detection patterns
            detection_patterns = [
                # File extension check
                r".*",
            ]

            # Add language-specific patterns
            if "{lang_name}".lower() in ["python", "py"]:
                detection_patterns.extend([
                    r"^\\s*def\\s+\\w+\\s*\\(",
                    r"^\\s*class\\s+\\w+",
                    r"^\\s*import\\s+\\w+",
                    r"^\\s*from\\s+\\w+\\s+import",
                    r"if\\s+__name__\\s*==\\s*[\\'\\\"]__main__[\\'\\\"]",
                ])
            elif "{lang_name}".lower() in ["javascript", "js", "typescript", "ts"]:
                detection_patterns.extend([
                    r"function\\s+\\w+\\s*\\(",
                    r"const\\s+\\w+\\s*=",
                    r"let\\s+\\w+\\s*=",
                    r"var\\s+\\w+\\s*=",
                    r"export\\s+(?:function|const|class)",
                    r"import\\s+.*from",
                ])
            elif "{lang_name}".lower() in ["java"]:
                detection_patterns.extend([
                    r"public\\s+class\\s+\\w+",
                    r"public\\s+static\\s+void\\s+main",
                    r"import\\s+java\\.",
                    r"package\\s+[\\w\\.]+;",
                ])
            elif "{lang_name}".lower() in ["go"]:
                detection_patterns.extend([
                    r"func\\s+\\w+\\s*\\(",
                    r"package\\s+\\w+",
                    r"import\\s+\\(",
                    r"type\\s+\\w+\\s+struct",
                ])
            elif "{lang_name}".lower() in ["rust", "rs"]:
                detection_patterns.extend([
                    r"fn\\s+\\w+\\s*\\(",
                    r"pub\\s+fn\\s+\\w+\\s*\\(",
                    r"impl\\s+.*\\{{",
                    r"struct\\s+\\w+",
                ])
            elif "{lang_name}".lower() in ["c", "cpp", "c++"]:
                detection_patterns.extend([
                    r"#include\\s*<.+\\.h>",
                    r"int\\s+main\\s*\\(",
                    r"void\\s+\\w+\\s*\\(",
                ])
            elif "{lang_name}".lower() in ["c#", "csharp"]:
                detection_patterns.extend([
                    r"using\\s+System",
                    r"public\\s+class\\s+\\w+",
                    r"static\\s+void\\s+Main",
                ])
            elif "{lang_name}".lower() in ["php"]:
                detection_patterns.extend([
                    r"<\\?php",
                    r"function\\s+\\w+\\s*\\(",
                    r"echo\\s+",
                    r"\\$\\w+",
                ])
            elif "{lang_name}".lower() in ["ruby", "rb"]:
                detection_patterns.extend([
                    r"def\\s+\\w+",
                    r"class\\s+\\w+",
                    r"require\\s+",
                    r"puts\\s+",
                ])
            elif "{lang_name}".lower() in ["shell", "bash", "sh"]:
                detection_patterns.extend([
                    r"^#!/bin/bash",
                    r"^#!/bin/sh",
                    r"function\\s+\\w+\\s*\\{{",
                    r"\\w+\\s*\\(\\)\\s*\\{{",
                ])

            score = 0
            for pattern in detection_patterns:
                if re.search(pattern, content, re.MULTILINE):
                    score += 1

            confidence = min(score / max(len(detection_patterns), 1), 1.0)
            is_detected = confidence > 0.3

            return PluginResult(
                success=True,
                data={{
                    'language': '{plugin_name}' if is_detected else 'unknown',
                    'confidence': confidence,
                    'score': score,
                    'patterns_matched': score
                }},
                confidence=confidence
            )

        except Exception as e:
            return PluginResult(
                success=False,
                data={{'language': 'unknown', 'confidence': 0.0}},
                errors=[str(e)],
                confidence=0.0
            )

    def analyze_content(self, file_path: Path) -> PluginResult:
        """Analyze {lang_name} file content for fuzzing patterns"""
        try:
            content = file_path.read_text(encoding='utf-8', errors='ignore')

            analysis = {{
                'functions': [],
                'classes': [],
                'imports': [],
                'fuzz_patterns': [],
                'total_lines': len(content.splitlines()),
                'code_lines': 0
            }}

            # Enhanced function extraction patterns for {lang_name}
            function_patterns = {function_patterns}
            for pattern in function_patterns:
                matches = re.findall(pattern, content, re.MULTILINE)
                analysis['functions'].extend(matches)

            # Remove duplicates and clean up
            analysis['functions'] = list(set([f for f in analysis['functions'] if f.strip()]))

            # Look for fuzz patterns
            fuzz_patterns = {keywords}
            for pattern in fuzz_patterns:
                if pattern in content.lower():
                    analysis['fuzz_patterns'].append(pattern)

            # Count code lines (non-empty, non-comment)
            code_lines = [
                line for line in content.splitlines()
                if line.strip() and not line.strip().startswith('//')
                and not line.strip().startswith('/*')
                and not line.strip().startswith('*')
                and not line.strip().startswith('#')
                and not line.strip().startswith('/*')
            ]
            analysis['code_lines'] = len(code_lines)

            return PluginResult(
                success=True,
                data=analysis,
                confidence=1.0,
                metadata={{'file_path': str(file_path)}}
            )

        except Exception as e:
            return PluginResult(
                success=False,
                data={{}},
                errors=[str(e)],
                confidence=0.0
            )

    def extract_keywords(self, file_path: Path) -> PluginResult:
        """Extract {lang_name}-specific keywords for fuzzing dictionary"""
        try:
            content = file_path.read_text(encoding='utf-8', errors='ignore')

            keywords = set()

            # Language-specific keywords
            language_keywords = {keywords}
            keywords.update(language_keywords)

            # Extract function names with enhanced patterns
            function_patterns = {function_patterns}
            for pattern in function_patterns:
                matches = re.findall(pattern, content)
                keywords.update(matches)

            # Extract string literals that might be used as arguments
            string_literals = re.findall(r'"([^"]*)"', content)
            interesting_strings = [s for s in string_literals if len(s) > 2 and ' ' not in s]
            keywords.update(interesting_strings[:50])

            return PluginResult(
                success=True,
                data={{'keywords': sorted(list(keywords))}},
                confidence=1.0,
                metadata={{'keyword_count': len(keywords)}}
            )

        except Exception as e:
            return PluginResult(
                success=False,
                data={{'keywords': []}},
                errors=[str(e)],
                confidence=0.0
            )
'''
        return template

    def create_human_language_plugin(self, lang_name: str, lang_code: str) -> str:
        """Create a human language plugin"""

        plugin_name = f"human_{lang_code.lower()}"

        template = f'''#!/usr/bin/env python3
"""
Human Language Plugin for {lang_name}
Generated by Universal Plugin Generator
"""

from pathlib import Path
from typing import Dict, Any, List
import re
import sys

# Add the parent directory to the path for imports
parent_dir = Path(__file__).parent.parent
sys.path.insert(0, str(parent_dir))

from rapid_expand import AnalysisPlugin, PluginResult

class {lang_name.title().replace(' ', '')}HumanLanguagePlugin(AnalysisPlugin):
    """Plugin for generating {lang_name} text for fuzzing"""

    @property
    def name(self) -> str:
        return "{plugin_name}"

    @property
    def analysis_type(self) -> str:
        return "human_language"

    @property
    def language_code(self) -> str:
        return "{lang_code}"

    @property
    def language_name(self) -> str:
        return "{lang_name}"

    def analyze(self, data: Any) -> PluginResult:
        """Generate {lang_name} text patterns for fuzzing"""
        try:
            # Get common words for {lang_name}
            common_words = self._get_common_words()

            # Generate various text patterns
            patterns = {{
                'common_words': common_words,
                'malformed_text': self._generate_malformed_text(),
                'unicode_attacks': self._generate_unicode_attacks(),
                'special_patterns': self._generate_special_patterns()
            }}

            return PluginResult(
                success=True,
                data=patterns,
                confidence=1.0,
                metadata={{
                    'language_code': '{lang_code}',
                    'language_name': '{lang_name}',
                    'word_count': len(common_words)
                }}
            )

        except Exception as e:
            return PluginResult(
                success=False,
                data={{}},
                errors=[str(e)],
                confidence=0.0
            )

    def _get_common_words(self) -> List[str]:
        """Get common words in {lang_name}"""
        # Common words for different languages
        if "{lang_code}".lower() == "en":
            return [
                "the", "be", "to", "of", "and", "a", "in", "that", "have", "I",
                "it", "for", "not", "on", "with", "he", "as", "you", "do", "at",
                "this", "but", "his", "by", "from", "they", "we", "say", "her", "she",
                "or", "an", "will", "my", "one", "all", "would", "there", "their", "what"
            ]
        elif "{lang_code}".lower() == "es":
            return [
                "el", "la", "de", "que", "y", "a", "en", "un", "es", "se",
                "no", "me", "si", "por", "te", "con", "lo", "como", "su", "más",
                "para", "pero", "sin", "todo", "ya", "muy", "sobre", "también", "hasta", "desde"
            ]
        elif "{lang_code}".lower() == "fr":
            return [
                "le", "de", "et", "à", "un", "il", "être", "et", "en", "avoir",
                "je", "ce", "mais", "pour", "dans", "qui", "il", "sur", "se", "ne",
                "pas", "plus", "son", "avec", "on", "elle", "deux", "même", "prendre", "P"
            ]
        elif "{lang_code}".lower() == "de":
            return [
                "der", "die", "und", "in", "den", "von", "zu", "das", "mit", "sich",
                "des", "auf", "für", "ist", "im", "dem", "nicht", "ein", "Die", "eine",
                "als", "auch", "es", "an", "werden", "aus", "er", "hat", "daß", "sie"
            ]
        elif "{lang_code}".lower() == "zh":
            return [
                "的", "一", "是", "在", "不", "了", "有", "和", "人", "这",
                "中", "大", "为", "上", "个", "国", "我", "以", "要", "他",
                "时", "来", "用", "们", "生", "到", "作", "地", "于", "出"
            ]
        elif "{lang_code}".lower() == "ar":
            return [
                "في", "من", "على", "و", "إلى", "أن", "هو", "مع", "لا", "كان",
                "له", "عن", "ما", "هذا", "قال", "لكن", "أو", "هي", "كل", "أنا"
            ]
        elif "{lang_code}".lower() == "ru":
            return [
                "и", "в", "не", "на", "я", "быть", "он", "с", "что", "а",
                "по", "это", "она", "как", "к", "у", "который", "мочь", "мы", "за"
            ]
        elif "{lang_code}".lower() == "ja":
            return [
                "の", "に", "は", "を", "た", "が", "で", "て", "と", "し",
                "れ", "さ", "ある", "いる", "も", "する", "から", "な", "こと", "として"
            ]
        else:
            # Generic fallback
            return [
                "word1", "word2", "word3", "word4", "word5",
                "word6", "word7", "word8", "word9", "word10"
            ]

    def _generate_malformed_text(self) -> List[str]:
        """Generate malformed text patterns for {lang_name}"""
        common_words = self._get_common_words()

        malformed = []

        # Generate various malformed patterns
        for word in common_words[:10]:
            # Add excessive spaces
            malformed.append(word + " " * 10 + word)
            # Add null bytes
            malformed.append(word + "\\x00" + word)
            # Add control characters
            malformed.append(word + "\\r\\n" + word)
            # Add very long words
            malformed.append(word * 100)

        return malformed

    def _generate_unicode_attacks(self) -> List[str]:
        """Generate Unicode-based attacks for {lang_name}"""
        attacks = []

        if "{lang_code}".lower() == "ar":
            # Arabic-specific attacks
            attacks.extend([
                "\\u061c",  # Arabic letter mark
                "\\u200e\\u200f",  # LTR/RTL marks
                "\\u202a\\u202b",  # RTL embedding
                "\\u202d\\u202e",  # RTL override
            ])

        if "{lang_code}".lower() == "ru":
            # Cyrillic homoglyphs for Latin characters
            homoglyphs = [
                ("a", "а"), ("e", "е"), ("o", "о"), ("p", "р"), ("c", "с"),
                ("y", "у"), ("x", "х"), ("k", "к"), ("b", "ь"), ("m", "м")
            ]
            for latin, cyrillic in homoglyphs:
                attacks.append(f"word{{latin}}word → word{{cyrillic}}word")

        # Universal Unicode attacks
        attacks.extend([
            "\\u0300" * 50,  # Combining grave accent
            "\\u0301" * 50,  # Combining acute accent
            "\\u200b" * 10,  # Zero width space
            "\\u200c" * 10,  # Zero width non-joiner
            "\\u200d" * 10,  # Zero width joiner
            "\\ufeff" * 5,   # Zero width no-break space
        ])

        return attacks

    def _generate_special_patterns(self) -> List[str]:
        """Generate special patterns for {lang_name}"""
        patterns = []

        # Very long strings
        patterns.append("A" * 10000)
        patterns.append("字" * 5000)  # Long Unicode

        # Mixed encoding
        patterns.append("Hello 世界 \\x80\\x81\\x82")

        # Surrogate pairs
        patterns.append("\\ud800\\udc00" * 10)

        # Mathematical symbols
        patterns.append("∑∏∆∇∈∉⊆⊇√∛∜∞∅")

        # Emoji
        patterns.append("😀😂🤣😊😍🤔🤨😮😱😨")

        # Language-specific patterns
        if "{lang_code}".lower() == "en":
            patterns.extend([
                "The quick brown fox jumps over the lazy dog",
                "Lorem ipsum dolor sit amet",
                "Hello, World!",
                "Test case with special chars: !@#$%^&*()",
                "SQL injection: ' OR '1'='1",
                "XSS: <script>alert('xss')</script>",
                "Path traversal: ../../../etc/passwd"
            ])

        return patterns
'''
        return template

def main():
    """Generate universal language plugins"""
    generator = UniversalPluginGenerator()

    # Programming languages to support
    programming_languages = {
        'c': {
            'name': 'C',
            'extensions': ['.c', '.h'],
            'keywords': ['int', 'char', 'void', 'struct', 'typedef', 'const', 'static', 'return', 'if', 'for', 'while'],
            'function_patterns': [r'(\w+)\s*\([^)]*\)\s*\{'],
            'fuzzer_engine': 'libfuzzer'
        },
        'cpp': {
            'name': 'C++',
            'extensions': ['.cpp', '.cc', '.cxx', '.c++', '.hpp'],
            'keywords': ['class', 'struct', 'namespace', 'template', 'typename', 'virtual', 'override', 'const', 'static', 'public', 'private'],
            'function_patterns': [r'(?:class\s+\w+\s*::\s*)?(\w+)\s*\([^)]*\)\s*(?:const)?\s*\{'],
            'fuzzer_engine': 'libfuzzer'
        },
        'rust': {
            'name': 'Rust',
            'extensions': ['.rs'],
            'keywords': ['fn', 'pub', 'struct', 'enum', 'impl', 'trait', 'let', 'mut', 'const', 'match', 'if', 'for', 'while'],
            'function_patterns': [r'fn\s+(\w+)\s*\(', r'pub\s+fn\s+(\w+)\s*\('],
            'fuzzer_engine': 'cargo-fuzz'
        },
        'python': {
            'name': 'Python',
            'extensions': ['.py', '.pyx', '.pyw', '.pyi'],
            'keywords': ['def', 'class', 'import', 'from', 'if', 'for', 'while', 'try', 'except', 'with', 'lambda', 'return', 'yield'],
            'function_patterns': [r'def\s+(\w+)\s*\(', r'async\s+def\s+(\w+)\s*\('],
            'fuzzer_engine': 'atheris'
        },
        'javascript': {
            'name': 'JavaScript',
            'extensions': ['.js', '.mjs', '.ts', '.tsx'],
            'keywords': ['function', 'const', 'let', 'var', 'class', 'export', 'import', 'async', 'await', 'try', 'catch', 'throw'],
            'function_patterns': [r'function\s+(\w+)\s*\(', r'const\s+(\w+)\s*=', r'let\s+(\w+)\s*=', r'var\s+(\w+)\s*='],
            'fuzzer_engine': 'jazzer.js'
        },
        'typescript': {
            'name': 'TypeScript',
            'extensions': ['.ts', '.tsx'],
            'keywords': ['interface', 'type', 'as', 'implements', 'extends', 'readonly', 'private', 'public', 'protected'],
            'function_patterns': [r'function\s+(\w+)\s*\(', r'const\s+(\w+)\s*=', r'let\s+(\w+)\s*=', r'var\s+(\w+)\s*='],
            'fuzzer_engine': 'jazzer.js'
        },
        'java': {
            'name': 'Java',
            'extensions': ['.java'],
            'keywords': ['public', 'private', 'class', 'interface', 'void', 'static', 'final', 'import', 'package', 'try', 'catch', 'throw'],
            'function_patterns': [r'public\s+(?:static\s+)?(?:\w+\s+)?(\w+)\s*\(', r'private\s+(?:static\s+)?(?:\w+\s+)?(\w+)\s*\('],
            'fuzzer_engine': 'jazzer'
        },
        'kotlin': {
            'name': 'Kotlin',
            'extensions': ['.kt', '.kts'],
            'keywords': ['fun', 'val', 'var', 'class', 'interface', 'object', 'companion', 'data', 'sealed', 'enum'],
            'function_patterns': [r'fun\s+(\w+)\s*\(', r'private\s+fun\s+(\w+)\s*\(', r'public\s+fun\s+(\w+)\s*\('],
            'fuzzer_engine': 'jazzer'
        },
        'scala': {
            'name': 'Scala',
            'extensions': ['.scala', '.sc'],
            'keywords': ['def', 'val', 'var', 'class', 'object', 'trait', 'type', 'case', 'match', 'if', 'for', 'while'],
            'function_patterns': [r'def\s+(\w+)\s*\(', r'private\s+def\s+(\w+)\s*\(', r'override\s+def\s+(\w+)\s*\('],
            'fuzzer_engine': 'jazzer'
        },
        'csharp': {
            'name': 'C#',
            'extensions': ['.cs'],
            'keywords': ['public', 'private', 'class', 'interface', 'void', 'static', 'async', 'await', 'try', 'catch', 'throw'],
            'function_patterns': [r'public\s+(?:static\s+)?(?:\w+\s+)?(\w+)\s*\(', r'private\s+(?:static\s+)?(?:\w+\s+)?(\w+)\s*\('],
            'fuzzer_engine': 'SharpFuzz'
        },
        'php': {
            'name': 'PHP',
            'extensions': ['.php', '.phtml'],
            'keywords': ['function', 'class', 'interface', 'public', 'private', 'static', 'try', 'catch', 'throw', 'echo'],
            'function_patterns': [r'function\s+(\w+)\s*\(', r'public\s+function\s+(\w+)\s*\(', r'private\s+function\s+(\w+)\s*\('],
            'fuzzer_engine': 'phpfuzz'
        },
        'ruby': {
            'name': 'Ruby',
            'extensions': ['.rb', '.rbw'],
            'keywords': ['def', 'class', 'module', 'if', 'unless', 'while', 'for', 'do', 'begin', 'rescue', 'ensure'],
            'function_patterns': [r'def\s+(\w+)', r'private\s+def\s+(\w+)', r'public\s+def\s+(\w+)'],
            'fuzzer_engine': 'ruby-fuzzer'
        },
        'shell': {
            'name': 'Shell',
            'extensions': ['.sh', '.bash', '.zsh'],
            'keywords': ['function', 'local', 'export', 'source', 'if', 'then', 'fi', 'for', 'do', 'done', 'while', 'case'],
            'function_patterns': [r'function\s+(\w+)\s*\(', r'(\w+)\s*\(\)\s*\{'],
            'fuzzer_engine': 'bash-fuzz'
        }
    }

    # Human languages to support
    human_languages = {
        'en': 'English',
        'es': 'Spanish',
        'fr': 'French',
        'de': 'German',
        'zh': 'Chinese',
        'ar': 'Arabic',
        'ru': 'Russian',
        'ja': 'Japanese',
        'hi': 'Hindi',
        'pt': 'Portuguese',
        'it': 'Italian',
        'ko': 'Korean',
        'th': 'Thai',
        'vi': 'Vietnamese'
    }

    print("🚀 Generating Universal Language Plugins...")
    print(f"📊 Programming Languages: {len(programming_languages)}")
    print(f"🌍 Human Languages: {len(human_languages)}")
    print(f"📦 Total Plugins: {len(programming_languages) + len(human_languages)}")
    print()

    # Generate programming language plugins
    print("💻 Generating Programming Language Plugins:")
    for lang_code, config in programming_languages.items():
        plugin_name = lang_code
        template = generator.create_programming_language_plugin(
            config['name'],
            plugin_name,
            config['extensions'],
            config['keywords'],
            config['function_patterns'],
            config['fuzzer_engine']
        )

        plugin_file = generator.plugins_dir / f"lang_{plugin_name}.py"
        plugin_file.write_text(template)

        print(f"  ✅ {config['name']} ({plugin_name}) - {config['fuzzer_engine']}")

    print()

    # Generate human language plugins
    print("🌍 Generating Human Language Plugins:")
    for lang_code, lang_name in human_languages.items():
        template = generator.create_human_language_plugin(lang_name, lang_code)

        plugin_file = generator.plugins_dir / f"human_{lang_code}.py"
        plugin_file.write_text(template)

        print(f"  ✅ {lang_name} ({lang_code})")

    print()
    print("🎉 Universal Plugin Generation Complete!")
    print(f"📂 Generated {len(programming_languages) + len(human_languages)} plugins in {generator.plugins_dir}/")
    print()
    print("🔧 Next Steps:")
    print("1. Test plugin loading: python3 rapid_expand.py --list-plugins")
    print("2. Test fuzzer generation: python3 rapid_expand.py --generate-fuzzers --source-dir <test_dir>")
    print("3. Review and enhance generated plugins as needed")
    print("4. Add more languages by extending this script")

if __name__ == "__main__":
    main()
